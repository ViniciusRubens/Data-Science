# -*- coding: utf-8 -*-
"""REGRESSÃO

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1HeGxIF1-sd42jh7kOTjTVPG0kX5WHXig

<a id="inicio"></a>
## REGRESSÃO

Esse notebook contém um projeto com modelo de regressão. O objetivo principal é tentar prever os preços de carros.

Vamos começar lendo os dados.
"""

import pandas as pd
import numpy as np
import math
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.model_selection import GridSearchCV
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error
import lightgbm as lgb

cars_df = pd.read_csv('OLX_Car_Data.csv', encoding = 'unicode_escape')
cars_df.describe(include='all')

"""Como os nomes dascolunas apresentam espaços, vamos renomear as colunas para remover os espaços:"""

cars_df.rename(columns = {'KMs Driven':'KMs_Driven',
                          'Registered City':'Registered_City',
                          'Transaction Type':'Transaction_Type'},
               inplace = True)

"""Quando utilizamos o método ```describe``` conseguimos ver algumas informações necessárias para fazer uma limpeza básica nos nossos dados.

Antes disso, vamos iniciar visualizando a quantidade de cada modelo de carro vendido na OLX.
"""

cars_df['Model'].value_counts()

"""Já que a coluna Model tem muitas categorias, vamos nomear todas com menos de 400 observações de 'Outros' e remover o valores nulos:"""

sorted(cars_df['Model'].value_counts()[cars_df['Model'].value_counts()>400].index)

models = ['Alto',
  'Bolan',
  'Charade',
  'City IVTEC',
  'Civic EXi',
  'Civic VTi Oriel Prosmatec',
  'Corolla GLI',
  'Corolla XLI',
  'Cultus VXR',
  'Cuore',
  'Khyber',
  'Mehran VX',
  'Mehran VXR',
  'Mira',
  'Vitz'
]

cars_df.loc[~cars_df['Model'].isin(models),'Model'] = 'Outros'

cars_df.dropna(axis=0, inplace=True)

"""Os outiliers mostram que existem dados muito distantes dos dados que mais aparecem. A distância interquartil é a distância entre Q1 (primeiro quartil) e Q3 (terceiro quartil). Para saber os outliers temos Q1 - 1.5IQR e Q3 + 1.5IQR.

Para remover os outliers:
"""

low = 0.05
high = 0.95
quant_df = cars_df.quantile([low, high])
cars_df = cars_df[(cars_df.KMs_Driven < quant_df.loc[high, "KMs_Driven"]) &
                  (cars_df.KMs_Driven > quant_df.loc[low, "KMs_Driven"]) &
                  (cars_df.Price < quant_df.loc[high, "Price"]) &
                  (cars_df.Price > quant_df.loc[low, "Price"]) &
                  (cars_df.Year < quant_df.loc[high, "Year"]) &
                  (cars_df.Year > quant_df.loc[low, "Year"])]

"""Sabemos que algumascolunas possuem valores binários, dessa forma, transformaremos elas:

"""

cars_df['is_new'] = 1
cars_df.loc[cars_df.Condition == 'Used', 'is_new'] = 0
cars_df.drop(['Condition'], axis=1, inplace=True)

cars_df['is_cash'] = 0
cars_df.loc[cars_df.Transaction_Type=='Cash', 'is_cash'] = 1
cars_df.drop('Transaction_Type', axis=1, inplace=True)

"""Com as outras colunas utilizaremos a técnica do One Hot Encoding.

Rótulos numéricos, no entanto, implicam que as categorias têm relações entre si, como uma ser menor ou ser seguida por outra. Para resolver isso, uma transformação quase sempre feita em dados categóricos é a chamada One Hot Encoding.

O que ela faz é criar uma coluna/variável numérica para cada categoria, com os valores 0 ou 1 representando a presença dessa categoria para cada registro.


"""

cars_df = pd.concat([cars_df.drop("Brand", axis=1), pd.get_dummies(cars_df.Brand, prefix='Brand')], axis=1)
cars_df = pd.concat([cars_df.drop("Fuel", axis=1), pd.get_dummies(cars_df.Fuel, prefix='Fuel')], axis=1)
cars_df = pd.concat([cars_df.drop("Registered_City", axis=1), pd.get_dummies(cars_df.Registered_City, prefix='RCity')], axis=1)
cars_df = pd.concat([cars_df.drop("Model", axis=1), pd.get_dummies(cars_df.Model, prefix='Model')], axis=1)

cars_df.describe(include='all')

"""Como nossa coluna alvo é o preço, dado que queremos realizar um predição deste valor, iremos retirar essa coluna."""

y, X = cars_df.Price, cars_df.drop('Price', axis=1)

print("X", X.shape)
print("y", y.shape)

"""Agora separaremos em treino, validação e teste:

"""

seed = 1

# separando treino e teste
X_training, X_test, y_training, y_test = train_test_split(X, y, random_state=seed, test_size=0.25) #, stratify=y)
print("Test set X", X_test.shape)
print("Test set y", y_test.shape)

# separando treino e validação
X_train, X_val, y_train, y_val = train_test_split(X_training, y_training, random_state=seed,
                                                  test_size=0.33) #, stratify=y_training)

print("Train set X", X_train.shape)
print("Train set y", y_train.shape)
print("Validation set X", X_val.shape)
print("Validation set y", y_val.shape)

"""## Modelagem

Agora partiremos para a segunda etapa de nosso projeto, o treinamento dos modelos.

#### Random Forest

Vamos iniciar treinando um modelo de *random forest* com validação cruzada e *grid search*. O *grid search* deve variar, pelo menos, os parâmetros *n_estimators* e *max_depth*, mas você pode incluir outros.

Após o treino, criaremos o *dataframe* ```cv_results``` com os resultados de cada iteração e o dicionário ```cv_best_params``` com os valores da melhor combinação de parâmetros.
"""

# Random Forest com validação cruzada e Grid Search

# definindo os valores possíveis dos parâmetros a serem testados
params = {'n_estimators': [5, 50, 100, 250, 500],
          'max_depth': [2, 5, 10, 25, 50]}

# criando o objeto do modelo com RandomForestRegressor
rf_model_cv_gs = RandomForestRegressor(random_state = seed)

# criando o objeto do grid search com GridSearchCV
grid_search = GridSearchCV(rf_model_cv_gs, param_grid=params, return_train_score=True, scoring='neg_root_mean_squared_error')

# treinando o modelo com o grid search
grid_search.fit(X_training, y_training) #por ser validação cruzada usamos o _training

# pegando os resultados da validação cruzada (cv_results)
cv_results = pd.DataFrame(grid_search.cv_results_)

# pegando e imprimindo a melhor combinação de hiperparâmetros
cv_best_params = grid_search.best_params_
print('\n Best hyperparameters:')
print(cv_best_params)

"""Agora, treinaremos o modelo final de *random forest* com os melhores parâmetros obtidos no *grid search* visto anteriormente."""

# imprimindo o score médio nas bases de treino
print("Average accuracy on train set: {:.3f} +/- {:.3f}".format(cv_results[cv_results.rank_test_score == 1].mean_train_score.values[0],
                                                                     cv_results[cv_results.rank_test_score == 1].std_train_score.values[0]))
# imprimindo o score médio nas bases de validação
print("Average accuracy on validation set: {:.3f} +/- {:.3f}".format(cv_results[cv_results.rank_test_score == 1].mean_test_score.values[0],
                                                                     cv_results[cv_results.rank_test_score == 1].std_test_score.values[0]))

# configurando o modelo com a melhor combinação de hiperparâmetros
rf_model_cv_gs.set_params(n_estimators = cv_best_params['n_estimators'],
                        max_depth = cv_best_params['max_depth'])

# treinando um modelo com a melhor combinação de hiperparâmetros
rf_model_cv_gs.fit(X_training, y_training)
best_model_params = rf_model_cv_gs.get_params()

"""Vamos obter um *dataframe* com a importância de cada variável do modelo de *random forest*."""

# desenhando o gráfico de impoartância de variáveis
features = X_training.columns
importances = rf_model_cv_gs.feature_importances_
indices = np.argsort(importances)

feature_importances_df = pd.DataFrame({'features': features,
                                       'importances': importances})

plt.title('Feature Importances')
plt.barh(range(len(importances[indices][-15:])), importances[indices][-15:], color='b', align='center')
plt.yticks(range(len(importances[indices][-15:])), [features[i] for i in indices[-15:]])
plt.xlabel('Relative Importance')
plt.show()

"""Por fim, vamos calcular o RMSE do modelo de *random forest* final na base de teste."""

y_test_pred_rf = rf_model_cv_gs.predict(X_test)
rmse_test_rf = math.sqrt(mean_squared_error(y_test, y_test_pred_rf))
print(rmse_test_rf)

"""#### Light GBM

Seguindo a mesma lógica, vamos treinar um modelo de Light GBM com validação cruzada e grid search. O grid search deve variar, pelo menos, os parâmetros learning_rate e n_estimators, mas você pode incluir outros.

Após o treino, crie o dataframe cv_results com os resultados de cada iteração e o dicionário cv_best_params com os valores da melhor combinação de parâmetros.
"""

import sys
!{sys.executable} -m pip install lightgbm

import lightgbm as lgb
import logging

# Defina o nível de registro para exibir apenas mensagens de aviso (WARNING) ou mais graves
logging.getLogger('lightgbm').setLevel(logging.WARNING)

# Light GBM com validação cruzada e Grid Search

# definindo os valores possíveis dos parâmetros a serem testados

# params = {'max_depth': [10, 50, 100],
#           'learning_rate': [0.01, 0.03, 0.1, 0.5],
#           'num_iterations': [100, 200, 500],
#           'min_data_in_leaf': [20, 50],
#           'min_gain_to_split': [0., 1, 5]}

params = {'learning_rate': [0.01, 0.03, 0.1, 0.5],
          'n_estimators': [5, 50, 100, 250, 500]} #que pode ser chamado de n_estimators

# criando o objeto do modelo com XGBClassifier
lgb_model_cv_gs = lgb.LGBMRegressor(random_state = seed)

# criando o objeto do grid search com GridSearchCV
grid_search = GridSearchCV(lgb_model_cv_gs, param_grid=params, return_train_score=True, scoring='neg_root_mean_squared_error')

# treinando o modelo com o grid search
grid_search.fit(X_training, y_training)

# pegando os resultados da validação cruzada (cv_results)
cv_results = pd.DataFrame(grid_search.cv_results_)

# pegando e imprimindo a melhor combinação de hiperparâmetros
cv_best_params = grid_search.best_params_
print('\n Best hyperparameters:')
print(cv_best_params)

"""Agora, vamos treinar o modelo final de *light GBM* com os melhores parâmetros obtidos no *grid search* do exercício anterior."""

# imprimindo o score médio nas bases de treino
print("Average accuracy on train set: {:.3f} +/- {:.3f}".format(cv_results[cv_results.rank_test_score == 1].mean_train_score.values[0],
                                                                     cv_results[cv_results.rank_test_score == 1].std_train_score.values[0]))

# imprimindo o score médio nas bases de validação
print("Average accuracy on validation set: {:.3f} +/- {:.3f}".format(cv_results[cv_results.rank_test_score == 1].mean_test_score.values[0],
                                                                     cv_results[cv_results.rank_test_score == 1].std_test_score.values[0]))

# configurando o modelo com a melhor combinação de hiperparâmetros
lgb_model_cv_gs.set_params(learning_rate = cv_best_params['learning_rate'],
                           n_estimators = cv_best_params['n_estimators'])

# treinando um modelo com a melhor combinação de hiperparâmetros
lgb_model_cv_gs.fit(X_training, y_training)
best_model_params = lgb_model_cv_gs.get_params()

"""Vamos obter um *dataframe* com a importância de cada variável do modelo de *light GBM*."""

# desenhando o gráfico de importância de variáveis
features = X_training.columns
importances = lgb_model_cv_gs.feature_importances_
indices = np.argsort(importances)

feature_importances_df = pd.DataFrame({'features': features,
                                       'importances': importances})

plt.title('Feature Importances')
plt.barh(range(len(importances[indices][-15:])), importances[indices][-15:], color='b', align='center')
plt.yticks(range(len(importances[indices][-15:])), [features[i] for i in indices[-15:]])
plt.xlabel('Relative Importance')
plt.show()

"""Por fim, vamos calcular o RMSE do modelo de *light GBM* final na base de teste."""

y_test_pred_lgb = lgb_model_cv_gs.predict(X_test)
rmse_test_lgb = math.sqrt(mean_squared_error(y_test, y_test_pred_lgb))
print(rmse_test_lgb)

"""#### Comparações

Vamos desenhar gráficos para comparar as duas previsões como fizamos com os dados e usá-los para responder as demais perguntas:
"""

# Desenhando o gráfico de valores previstos por valores reais para ambos os modelos

plt.figure(figsize=(16,10))
plt.title('Pakistan car prices - Predicted vs Real',fontsize=20)
df = pd.DataFrame({'real':y_val,'Random Forest':rf_model_cv_gs.predict(X_val),
                   'LGBM':lgb_model_cv_gs.predict(X_val)})
df = df.sample(200)
df.sort_values(by=['real'],ascending=True,inplace=True)
df = df.reset_index(drop=True)
plt.plot(df)
plt.legend(['Real price','Predicted RF price','Predicted LGBM price'],fontsize=20)
plt.ylabel('$ Price',fontsize=20)
plt.xlabel('Observations ordered by price',fontsize=20)
plt.show()

plt.figure(figsize=(16,10))
plt.title('Pakistan car prices - Predicted vs Real',fontsize=20)
plt.scatter(x=df['real'],y=df['Random Forest'],c='y')
plt.scatter(x=df['real'],y=df['LGBM'],c='g')
plt.plot([0,1750000],[0,1750000],'k--')
# plt.axis([0,1750000,0,1750000])
plt.legend(['Real price','Predicted RF price','Predicted LGBM price'],fontsize=20)
plt.xlabel('Real price',fontsize=20)
plt.ylabel('Predicted price',fontsize=20)
plt.show()